{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-05T09:13:48.675520Z",
     "iopub.status.busy": "2021-12-05T09:13:48.674825Z",
     "iopub.status.idle": "2021-12-05T09:13:48.682415Z",
     "shell.execute_reply": "2021-12-05T09:13:48.681651Z",
     "shell.execute_reply.started": "2021-12-05T09:13:48.675478Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:14:24.948618Z",
     "iopub.status.busy": "2021-12-05T09:14:24.948296Z",
     "iopub.status.idle": "2021-12-05T09:14:25.143130Z",
     "shell.execute_reply": "2021-12-05T09:14:25.142436Z",
     "shell.execute_reply.started": "2021-12-05T09:14:24.948583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:14:56.318187Z",
     "iopub.status.busy": "2021-12-05T09:14:56.317913Z",
     "iopub.status.idle": "2021-12-05T09:14:56.324053Z",
     "shell.execute_reply": "2021-12-05T09:14:56.323310Z",
     "shell.execute_reply.started": "2021-12-05T09:14:56.318157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (27481, 4)\n",
      "shape of the test data:  (3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the train data: \", df_train.shape)\n",
    "print(\"shape of the test data: \", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:01.318978Z",
     "iopub.status.busy": "2021-12-05T09:15:01.318305Z",
     "iopub.status.idle": "2021-12-05T09:15:02.074537Z",
     "shell.execute_reply": "2021-12-05T09:15:02.073772Z",
     "shell.execute_reply.started": "2021-12-05T09:15:01.318933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24732, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(df_train,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:06.001992Z",
     "iopub.status.busy": "2021-12-05T09:15:06.001254Z",
     "iopub.status.idle": "2021-12-05T09:15:06.037643Z",
     "shell.execute_reply": "2021-12-05T09:15:06.036704Z",
     "shell.execute_reply.started": "2021-12-05T09:15:06.001953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24731, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "# filling na values with \"\" \n",
    "X_train.dropna(inplace=True)\n",
    "X_val.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:11.521133Z",
     "iopub.status.busy": "2021-12-05T09:15:11.520847Z",
     "iopub.status.idle": "2021-12-05T09:15:22.530513Z",
     "shell.execute_reply": "2021-12-05T09:15:22.529746Z",
     "shell.execute_reply.started": "2021-12-05T09:15:11.521082Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# using Xl-net tokenizer to tokenize the text into input IDs that model can make sense of.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_models/xlnet/xlnet_base_cased_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:22.532409Z",
     "iopub.status.busy": "2021-12-05T09:15:22.532168Z",
     "iopub.status.idle": "2021-12-05T09:15:22.584392Z",
     "shell.execute_reply": "2021-12-05T09:15:22.583544Z",
     "shell.execute_reply.started": "2021-12-05T09:15:22.532376Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"xlnet_base_cased_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:22.586082Z",
     "iopub.status.busy": "2021-12-05T09:15:22.585805Z",
     "iopub.status.idle": "2021-12-05T09:15:23.082815Z",
     "shell.execute_reply": "2021-12-05T09:15:23.082060Z",
     "shell.execute_reply.started": "2021-12-05T09:15:22.586045Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## converting train and validation pandas dataset into huggingFace Dataset format.\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "validation_data = Dataset.from_pandas(X_val)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:27.004417Z",
     "iopub.status.busy": "2021-12-05T09:15:27.003857Z",
     "iopub.status.idle": "2021-12-05T09:15:27.740761Z",
     "shell.execute_reply": "2021-12-05T09:15:27.740023Z",
     "shell.execute_reply.started": "2021-12-05T09:15:27.004379Z"
    }
   },
   "outputs": [],
   "source": [
    "context = train_data[0][\"text\"]\n",
    "question = train_data[0][\"sentiment\"]\n",
    "\n",
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:32.187993Z",
     "iopub.status.busy": "2021-12-05T09:15:32.187395Z",
     "iopub.status.idle": "2021-12-05T09:15:40.901880Z",
     "shell.execute_reply": "2021-12-05T09:15:40.900933Z",
     "shell.execute_reply.started": "2021-12-05T09:15:32.187952Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to tokenize each sample.\n",
    "def preprocess(example):\n",
    "  return tokenizer(\n",
    "    example[\"sentiment\"],\n",
    "    example[\"text\"],\n",
    "    return_offsets_mapping = True\n",
    ")\n",
    "\n",
    "check_dataset = train_data.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "check_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:40.903838Z",
     "iopub.status.busy": "2021-12-05T09:15:40.903508Z",
     "iopub.status.idle": "2021-12-05T09:15:47.037268Z",
     "shell.execute_reply": "2021-12-05T09:15:47.036324Z",
     "shell.execute_reply.started": "2021-12-05T09:15:40.903802Z"
    }
   },
   "outputs": [],
   "source": [
    "## finding the maximum length of a sequece after tokenization\n",
    "MAX_LENGTH = 0\n",
    "for i in check_dataset:\n",
    "  length = len(i[\"input_ids\"])\n",
    "  if length > MAX_LENGTH:\n",
    "    MAX_LENGTH = length\n",
    "    \n",
    "print(\"Max length of a sequence after tokenization: \", MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:47.039415Z",
     "iopub.status.busy": "2021-12-05T09:15:47.039138Z",
     "iopub.status.idle": "2021-12-05T09:15:47.051434Z",
     "shell.execute_reply": "2021-12-05T09:15:47.050576Z",
     "shell.execute_reply.started": "2021-12-05T09:15:47.039376Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "  inputs = tokenizer(\n",
    "    examples[\"sentiment\"],\n",
    "    examples[\"text\"],\n",
    "    max_length = MAX_LENGTH,\n",
    "    return_offsets_mapping = True,\n",
    "    padding = \"max_length\",\n",
    "    )\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  #print(inputs[\"offset_mapping\"])\n",
    "\n",
    "  for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "\n",
    "    answer = examples[\"selected_text\"][i]\n",
    "    question = examples[\"sentiment\"][i]\n",
    "    context = examples[\"text\"][i]\n",
    "    \n",
    "    \n",
    "    # print(\"context: \", context)\n",
    "    # print(\"Answer: \", answer)\n",
    "    # finding the index of first character and the index of last character of answer in the context(tweet_text)\n",
    "    \n",
    "    start_char = 0\n",
    "    end_char  = 0\n",
    "    for idx,ch in enumerate(context):\n",
    "      count = idx\n",
    "      flag = True\n",
    "      for j in answer:\n",
    "        if context[count] == j:\n",
    "          count +=1\n",
    "        else:\n",
    "          flag = False\n",
    "          break\n",
    "      if flag:\n",
    "        start_char = idx\n",
    "        break\n",
    "\n",
    "    end_char = start_char + len(answer)\n",
    "    # print(\"Input ids: \", inputs[\"input_ids\"])\n",
    "    # print(\"*\"*200)\n",
    "    # print((tokenizer.decode(inputs[\"input_ids\"][i])))\n",
    "    # print(\"*\"*200)\n",
    "    # print(len(inputs[\"input_ids\"]))\n",
    "    # print(\"*\"*200)\n",
    "    # print((inputs.sequence_ids(i)))\n",
    "    # print(inputs[\"token_type_ids\"][i])\n",
    "    # finding the start  and end of the context\n",
    "    # sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    token_type_ids = inputs[\"token_type_ids\"][i]\n",
    "\n",
    "    idx = 0\n",
    "    try:\n",
    "      while token_type_ids[idx]!=1:\n",
    "        idx+=1\n",
    "      context_start = idx\n",
    "\n",
    "      while token_type_ids[idx] ==1:\n",
    "        idx+=1\n",
    "        if idx == len(token_type_ids):\n",
    "          break\n",
    "      context_end = idx-1\n",
    "    except:\n",
    "      print(token_type_ids)\n",
    "    # finding the start position \n",
    "    # print(\"Shart Char: \", start_char)\n",
    "    # print(\"End char: \", end_char)\n",
    "    # print(\"Context Start: \", context_start)\n",
    "    # print(\"Context end: \", context_end)\n",
    "\n",
    "    idx = context_start\n",
    "    while idx <= context_end and offset[idx][0] <= start_char:\n",
    "      idx+=1\n",
    "    start_positions.append(idx-1)\n",
    "    \n",
    "    idx = context_end -1\n",
    "    while idx >= context_start and offset[idx][1] >= end_char:\n",
    "      idx-=1\n",
    "    end_positions.append(idx+1)\n",
    "  \n",
    "  inputs[\"start_positions\"] = start_positions\n",
    "  inputs[\"end_positions\"] = end_positions\n",
    "   \n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:15:48.498138Z",
     "iopub.status.busy": "2021-12-05T09:15:48.497588Z",
     "iopub.status.idle": "2021-12-05T09:16:18.968363Z",
     "shell.execute_reply": "2021-12-05T09:16:18.967554Z",
     "shell.execute_reply.started": "2021-12-05T09:15:48.498082Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_train_data = train_data.map(preprocess_training_examples,batched=True)\n",
    "processed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:18.970447Z",
     "iopub.status.busy": "2021-12-05T09:16:18.970188Z",
     "iopub.status.idle": "2021-12-05T09:16:18.981183Z",
     "shell.execute_reply": "2021-12-05T09:16:18.980373Z",
     "shell.execute_reply.started": "2021-12-05T09:16:18.970411Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 2000\n",
    "answer = processed_train_data[idx][\"selected_text\"]\n",
    "\n",
    "start = processed_train_data[idx][\"start_positions\"]\n",
    "end = processed_train_data[idx][\"end_positions\"]\n",
    "labeled_answer = tokenizer.decode(processed_train_data[idx][\"input_ids\"][start : end +1 ])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}\")\n",
    "print(f\"labels give: {labeled_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:18.982552Z",
     "iopub.status.busy": "2021-12-05T09:16:18.982305Z",
     "iopub.status.idle": "2021-12-05T09:16:22.462127Z",
     "shell.execute_reply": "2021-12-05T09:16:22.461330Z",
     "shell.execute_reply.started": "2021-12-05T09:16:18.982516Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(preprocess_training_examples, batched = True)\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:22.464475Z",
     "iopub.status.busy": "2021-12-05T09:16:22.464209Z",
     "iopub.status.idle": "2021-12-05T09:16:42.658377Z",
     "shell.execute_reply": "2021-12-05T09:16:42.657511Z",
     "shell.execute_reply.started": "2021-12-05T09:16:22.464431Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:42.660039Z",
     "iopub.status.busy": "2021-12-05T09:16:42.659786Z",
     "iopub.status.idle": "2021-12-05T09:16:42.964093Z",
     "shell.execute_reply": "2021-12-05T09:16:42.963315Z",
     "shell.execute_reply.started": "2021-12-05T09:16:42.660003Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = processed_train_data.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"start_positions\",\n",
    "        \"end_positions\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\"\n",
    "    ],\n",
    "    dummy_labels=True,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:42.967256Z",
     "iopub.status.busy": "2021-12-05T09:16:42.965320Z",
     "iopub.status.idle": "2021-12-05T09:16:43.006019Z",
     "shell.execute_reply": "2021-12-05T09:16:43.005341Z",
     "shell.execute_reply.started": "2021-12-05T09:16:42.967221Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"],\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:43.008178Z",
     "iopub.status.busy": "2021-12-05T09:16:43.007836Z",
     "iopub.status.idle": "2021-12-05T09:16:43.026940Z",
     "shell.execute_reply": "2021-12-05T09:16:43.026225Z",
     "shell.execute_reply.started": "2021-12-05T09:16:43.008141Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_epochs = 10\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.001,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "#tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T09:16:45.910010Z",
     "iopub.status.busy": "2021-12-05T09:16:45.909144Z",
     "iopub.status.idle": "2021-12-05T10:28:39.310473Z",
     "shell.execute_reply": "2021-12-05T10:28:39.309779Z",
     "shell.execute_reply.started": "2021-12-05T09:16:45.909960Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "earlyStop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=1, verbose=0,\n",
    "    mode='auto',baseline=None, restore_best_weights=True\n",
    "    )\n",
    "# We're going to do validation afterwards, so no validation mid-training\n",
    "model.fit(tf_train_dataset, epochs=num_train_epochs,callbacks = [earlyStop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:47:00.322818Z",
     "iopub.status.busy": "2021-12-05T10:47:00.322062Z",
     "iopub.status.idle": "2021-12-05T10:47:00.341617Z",
     "shell.execute_reply": "2021-12-05T10:47:00.340765Z",
     "shell.execute_reply.started": "2021-12-05T10:47:00.322770Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:45:03.868724Z",
     "iopub.status.busy": "2021-12-05T10:45:03.868459Z",
     "iopub.status.idle": "2021-12-05T10:45:03.874372Z",
     "shell.execute_reply": "2021-12-05T10:45:03.873518Z",
     "shell.execute_reply.started": "2021-12-05T10:45:03.868696Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add_loss(tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:45:08.604591Z",
     "iopub.status.busy": "2021-12-05T10:45:08.604328Z",
     "iopub.status.idle": "2021-12-05T10:45:08.609816Z",
     "shell.execute_reply": "2021-12-05T10:45:08.609150Z",
     "shell.execute_reply.started": "2021-12-05T10:45:08.604563Z"
    }
   },
   "outputs": [],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:47:47.781330Z",
     "iopub.status.busy": "2021-12-05T10:47:47.781032Z",
     "iopub.status.idle": "2021-12-05T10:47:48.633400Z",
     "shell.execute_reply": "2021-12-05T10:47:48.632592Z",
     "shell.execute_reply.started": "2021-12-05T10:47:47.781299Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"xlnet_base_cased_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:52:57.501929Z",
     "iopub.status.busy": "2021-12-05T10:52:57.501649Z",
     "iopub.status.idle": "2021-12-05T10:53:22.501163Z",
     "shell.execute_reply": "2021-12-05T10:53:22.500166Z",
     "shell.execute_reply.started": "2021-12-05T10:52:57.501896Z"
    }
   },
   "outputs": [],
   "source": [
    "!zip -r file.zip ./xlnet_base_cased_model/tf_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:54:32.944873Z",
     "iopub.status.busy": "2021-12-05T10:54:32.944169Z",
     "iopub.status.idle": "2021-12-05T10:54:32.948467Z",
     "shell.execute_reply": "2021-12-05T10:54:32.947615Z",
     "shell.execute_reply.started": "2021-12-05T10:54:32.944834Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:55:10.159834Z",
     "iopub.status.busy": "2021-12-05T10:55:10.159222Z",
     "iopub.status.idle": "2021-12-05T10:55:10.165964Z",
     "shell.execute_reply": "2021-12-05T10:55:10.165127Z",
     "shell.execute_reply.started": "2021-12-05T10:55:10.159792Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'./xlnet_base_cased_model/tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:56:46.475025Z",
     "iopub.status.busy": "2021-12-05T10:56:46.474741Z",
     "iopub.status.idle": "2021-12-05T10:56:46.489969Z",
     "shell.execute_reply": "2021-12-05T10:56:46.489160Z",
     "shell.execute_reply.started": "2021-12-05T10:56:46.474997Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_data = Dataset.from_pandas(df_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:57:40.839654Z",
     "iopub.status.busy": "2021-12-05T10:57:40.839083Z",
     "iopub.status.idle": "2021-12-05T10:57:40.845554Z",
     "shell.execute_reply": "2021-12-05T10:57:40.844807Z",
     "shell.execute_reply.started": "2021-12-05T10:57:40.839616Z"
    }
   },
   "outputs": [],
   "source": [
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    token_type_ids = inputs[\"token_type_ids\"][i]\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if token_type_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:57:41.650794Z",
     "iopub.status.busy": "2021-12-05T10:57:41.650259Z",
     "iopub.status.idle": "2021-12-05T10:57:44.596703Z",
     "shell.execute_reply": "2021-12-05T10:57:44.595977Z",
     "shell.execute_reply.started": "2021-12-05T10:57:41.650759Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:59:43.436254Z",
     "iopub.status.busy": "2021-12-05T10:59:43.435976Z",
     "iopub.status.idle": "2021-12-05T10:59:43.471179Z",
     "shell.execute_reply": "2021-12-05T10:59:43.470501Z",
     "shell.execute_reply.started": "2021-12-05T10:59:43.436225Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:57:59.397339Z",
     "iopub.status.busy": "2021-12-05T10:57:59.396946Z",
     "iopub.status.idle": "2021-12-05T10:58:01.937597Z",
     "shell.execute_reply": "2021-12-05T10:58:01.936677Z",
     "shell.execute_reply.started": "2021-12-05T10:57:59.397296Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_test_data = test_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:59:47.201009Z",
     "iopub.status.busy": "2021-12-05T10:59:47.200457Z",
     "iopub.status.idle": "2021-12-05T10:59:47.238750Z",
     "shell.execute_reply": "2021-12-05T10:59:47.237985Z",
     "shell.execute_reply.started": "2021-12-05T10:59:47.200969Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_test_dataset = processed_test_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T10:59:50.838943Z",
     "iopub.status.busy": "2021-12-05T10:59:50.838678Z",
     "iopub.status.idle": "2021-12-05T11:00:01.247418Z",
     "shell.execute_reply": "2021-12-05T11:00:01.246065Z",
     "shell.execute_reply.started": "2021-12-05T10:59:50.838910Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-05T10:58:39.980466Z",
     "iopub.status.idle": "2021-12-05T10:58:39.981086Z",
     "shell.execute_reply": "2021-12-05T10:58:39.980872Z",
     "shell.execute_reply.started": "2021-12-05T10:58:39.980848Z"
    }
   },
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "n_best = 20\n",
    "\n",
    "def predict_answers(start_logits,end_logits, inputs, examples):\n",
    "    predicted_answers = []\n",
    "    for i in range(len(examples[\"textID\"])):\n",
    "        start_logit = start_logits[i]\n",
    "        end_logit = end_logits[i]\n",
    "        context = examples[\"text\"][i]\n",
    "\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "\n",
    "        flag = False\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # skip answer that are not in the context.\n",
    "                if offset[start_index] is None or offset[end_index] is None:\n",
    "                    continue\n",
    "                # skip answer with length that is either < 0\n",
    "                if end_index < start_index:\n",
    "                    continue\n",
    "\n",
    "                flag = True\n",
    "                answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                predicted_answers.append(answer)\n",
    "                break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            predicted_answers.append(context)\n",
    "    return predicted_answers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
