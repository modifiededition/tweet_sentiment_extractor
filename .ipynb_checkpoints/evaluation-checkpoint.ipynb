{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.614311Z",
     "iopub.status.busy": "2021-12-06T11:57:49.614058Z",
     "iopub.status.idle": "2021-12-06T11:57:49.630832Z",
     "shell.execute_reply": "2021-12-06T11:57:49.630142Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.614283Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.754385Z",
     "iopub.status.busy": "2021-12-06T11:57:49.753780Z",
     "iopub.status.idle": "2021-12-06T11:57:49.842442Z",
     "shell.execute_reply": "2021-12-06T11:57:49.841769Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.754351Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.926686Z",
     "iopub.status.busy": "2021-12-06T11:57:49.924916Z",
     "iopub.status.idle": "2021-12-06T11:57:49.932434Z",
     "shell.execute_reply": "2021-12-06T11:57:49.931494Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.926654Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the train data: \", df_train.shape)\n",
    "print(\"shape of the test data: \", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:50.092686Z",
     "iopub.status.busy": "2021-12-06T11:57:50.092466Z",
     "iopub.status.idle": "2021-12-06T11:57:50.106658Z",
     "shell.execute_reply": "2021-12-06T11:57:50.105926Z",
     "shell.execute_reply.started": "2021-12-06T11:57:50.092661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(df_train,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:50.365204Z",
     "iopub.status.busy": "2021-12-06T11:57:50.364623Z",
     "iopub.status.idle": "2021-12-06T11:57:50.392296Z",
     "shell.execute_reply": "2021-12-06T11:57:50.391650Z",
     "shell.execute_reply.started": "2021-12-06T11:57:50.365172Z"
    }
   },
   "outputs": [],
   "source": [
    "# filling na values with \"\" \n",
    "X_train.dropna(inplace=True)\n",
    "X_val.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:51.349465Z",
     "iopub.status.busy": "2021-12-06T11:57:51.348986Z",
     "iopub.status.idle": "2021-12-06T11:57:51.380292Z",
     "shell.execute_reply": "2021-12-06T11:57:51.379492Z",
     "shell.execute_reply.started": "2021-12-06T11:57:51.349418Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## converting train and validation pandas dataset into huggingFace Dataset format.\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "validation_data = Dataset.from_pandas(X_val)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:00:27.236319Z",
     "iopub.status.busy": "2021-12-06T12:00:27.235699Z",
     "iopub.status.idle": "2021-12-06T12:00:27.247134Z",
     "shell.execute_reply": "2021-12-06T12:00:27.246251Z",
     "shell.execute_reply.started": "2021-12-06T12:00:27.236268Z"
    }
   },
   "outputs": [],
   "source": [
    "n_best = 20\n",
    "\n",
    "def predict_answers(inputs):\n",
    "    predicted_answer = []\n",
    "    for i in range(len(inputs[\"offset_mapping\"])):\n",
    "        start_logit = inputs[\"start_logits\"][i]\n",
    "        end_logit = inputs[\"end_logits\"][i]\n",
    "        context = inputs[\"text\"][i]\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "        \n",
    "        flag = False\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # skip answer that are not in the context.\n",
    "                if offset[start_index] is None or offset[end_index] is None:\n",
    "                    continue\n",
    "                # skip answer with length that is either < 0\n",
    "                if end_index < start_index:\n",
    "                    continue\n",
    "                flag = True\n",
    "                answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                predicted_answer.append(answer)\n",
    "                break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            predicted_answer.append(answer)\n",
    "    return {\"predicted_answer\":predicted_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:54.524528Z",
     "iopub.status.busy": "2021-12-06T11:57:54.524275Z",
     "iopub.status.idle": "2021-12-06T11:57:54.529942Z",
     "shell.execute_reply": "2021-12-06T11:57:54.528964Z",
     "shell.execute_reply.started": "2021-12-06T11:57:54.524500Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Baseline Model: Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:55.296275Z",
     "iopub.status.busy": "2021-12-06T11:57:55.296013Z",
     "iopub.status.idle": "2021-12-06T11:58:13.519384Z",
     "shell.execute_reply": "2021-12-06T11:58:13.518568Z",
     "shell.execute_reply.started": "2021-12-06T11:57:55.296247Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../input/tokenizerbert\",local_files_only=True)\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"../input/bert-base-qa-model\",local_files_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:13.521813Z",
     "iopub.status.busy": "2021-12-06T11:58:13.521326Z",
     "iopub.status.idle": "2021-12-06T11:58:13.528554Z",
     "shell.execute_reply": "2021-12-06T11:58:13.527884Z",
     "shell.execute_reply.started": "2021-12-06T11:58:13.521775Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 112\n",
    "\n",
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    token_type_ids = inputs[\"token_type_ids\"][i]\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if token_type_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:13.529673Z",
     "iopub.status.busy": "2021-12-06T11:58:13.529412Z",
     "iopub.status.idle": "2021-12-06T11:58:15.535902Z",
     "shell.execute_reply": "2021-12-06T11:58:15.535001Z",
     "shell.execute_reply.started": "2021-12-06T11:58:13.529639Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:15.538577Z",
     "iopub.status.busy": "2021-12-06T11:58:15.538303Z",
     "iopub.status.idle": "2021-12-06T11:58:15.803495Z",
     "shell.execute_reply": "2021-12-06T11:58:15.802651Z",
     "shell.execute_reply.started": "2021-12-06T11:58:15.538541Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:15.805372Z",
     "iopub.status.busy": "2021-12-06T11:58:15.805020Z",
     "iopub.status.idle": "2021-12-06T11:58:43.446426Z",
     "shell.execute_reply": "2021-12-06T11:58:43.445675Z",
     "shell.execute_reply.started": "2021-12-06T11:58:15.805335Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:00:35.633240Z",
     "iopub.status.busy": "2021-12-06T12:00:35.632499Z",
     "iopub.status.idle": "2021-12-06T12:00:37.643106Z",
     "shell.execute_reply": "2021-12-06T12:00:37.642448Z",
     "shell.execute_reply.started": "2021-12-06T12:00:35.633203Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data.set_format(\"pandas\")\n",
    "processed_val_df =  processed_val_data[:]\n",
    "\n",
    "processed_val_df[\"start_logits\"] = start_logits.tolist()\n",
    "processed_val_df[\"end_logits\"] = end_logits.tolist()\n",
    "\n",
    "processed_val_df[\"text\"] = validation_data[\"text\"]\n",
    "\n",
    "bert_final_val_data = Dataset.from_pandas(processed_val_df)\n",
    "\n",
    "bert_final_val_data = bert_final_val_data.map(predict_answers,batched=True)\n",
    "bert_final_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:04:56.137228Z",
     "iopub.status.busy": "2021-12-06T12:04:56.136391Z",
     "iopub.status.idle": "2021-12-06T12:04:56.180208Z",
     "shell.execute_reply": "2021-12-06T12:04:56.179294Z",
     "shell.execute_reply.started": "2021-12-06T12:04:56.137179Z"
    }
   },
   "outputs": [],
   "source": [
    "theoritcal_answers = processed_val_data[\"selected_text\"]\n",
    "\n",
    "# calculating the jaccard score\n",
    "score = 0\n",
    "predicted_val_answers_by_bert = bert_final_val_data[\"predicted_answer\"]\n",
    "for i in range(len(theoritcal_answers)):\n",
    "  score += jaccard(theoritcal_answers[i],predicted_val_answers_by_bert[i])\n",
    "\n",
    "score /= len(theoritcal_answers)\n",
    "print(\"Jaccard score on validation data: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the best model: Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:02:31.523240Z",
     "iopub.status.busy": "2021-12-06T12:02:31.522498Z",
     "iopub.status.idle": "2021-12-06T12:02:39.519020Z",
     "shell.execute_reply": "2021-12-06T12:02:39.518259Z",
     "shell.execute_reply.started": "2021-12-06T12:02:31.523196Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../input/robertatokenizer\",local_files_only=True)\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"../input/robertamodel\",local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:02:56.441495Z",
     "iopub.status.busy": "2021-12-06T12:02:56.441201Z",
     "iopub.status.idle": "2021-12-06T12:02:56.447834Z",
     "shell.execute_reply": "2021-12-06T12:02:56.446917Z",
     "shell.execute_reply.started": "2021-12-06T12:02:56.441464Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 73\n",
    "\n",
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:07.344151Z",
     "iopub.status.busy": "2021-12-06T12:03:07.343524Z",
     "iopub.status.idle": "2021-12-06T12:03:08.820631Z",
     "shell.execute_reply": "2021-12-06T12:03:08.819802Z",
     "shell.execute_reply.started": "2021-12-06T12:03:07.344112Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:16.056052Z",
     "iopub.status.busy": "2021-12-06T12:03:16.053625Z",
     "iopub.status.idle": "2021-12-06T12:03:16.091317Z",
     "shell.execute_reply": "2021-12-06T12:03:16.090628Z",
     "shell.execute_reply.started": "2021-12-06T12:03:16.056012Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:25.180679Z",
     "iopub.status.busy": "2021-12-06T12:03:25.180400Z",
     "iopub.status.idle": "2021-12-06T12:03:43.245669Z",
     "shell.execute_reply": "2021-12-06T12:03:43.244871Z",
     "shell.execute_reply.started": "2021-12-06T12:03:25.180649Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:49.755271Z",
     "iopub.status.busy": "2021-12-06T12:03:49.755008Z",
     "iopub.status.idle": "2021-12-06T12:03:50.833955Z",
     "shell.execute_reply": "2021-12-06T12:03:50.833275Z",
     "shell.execute_reply.started": "2021-12-06T12:03:49.755243Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data.set_format(\"pandas\")\n",
    "processed_val_df =  processed_val_data[:]\n",
    "\n",
    "processed_val_df[\"start_logits\"] = start_logits.tolist()\n",
    "processed_val_df[\"end_logits\"] = end_logits.tolist()\n",
    "\n",
    "processed_val_df[\"text\"] = validation_data[\"text\"]\n",
    "\n",
    "roberta_final_val_data = Dataset.from_pandas(processed_val_df)\n",
    "\n",
    "roberta_final_val_data = roberta_final_val_data.map(predict_answers,batched=True)\n",
    "roberta_final_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:04:58.777982Z",
     "iopub.status.busy": "2021-12-06T12:04:58.777211Z",
     "iopub.status.idle": "2021-12-06T12:04:58.813397Z",
     "shell.execute_reply": "2021-12-06T12:04:58.812677Z",
     "shell.execute_reply.started": "2021-12-06T12:04:58.777943Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculating the jaccard score\n",
    "score = 0\n",
    "predicted_val_answers_by_roberta = roberta_final_val_data[\"predicted_answer\"]\n",
    "for i in range(len(theoritcal_answers)):\n",
    "  score += jaccard(theoritcal_answers[i],predicted_val_answers_by_roberta[i])\n",
    "\n",
    "score /= len(theoritcal_answers)\n",
    "print(\"Jaccard score on validation data: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison on predictions between basline model-bert and the best model roberta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:11:13.800585Z",
     "iopub.status.busy": "2021-12-06T12:11:13.800310Z",
     "iopub.status.idle": "2021-12-06T12:11:13.806714Z",
     "shell.execute_reply": "2021-12-06T12:11:13.805662Z",
     "shell.execute_reply.started": "2021-12-06T12:11:13.800555Z"
    }
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Jaccard score on validation data\"]\n",
    "x.add_row([\"Bert-base-cased\", 0.67])\n",
    "x.add_row([\"Roberta-base-cased\", 0.71])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:08:23.946294Z",
     "iopub.status.busy": "2021-12-06T12:08:23.946021Z",
     "iopub.status.idle": "2021-12-06T12:08:23.957988Z",
     "shell.execute_reply": "2021-12-06T12:08:23.957214Z",
     "shell.execute_reply.started": "2021-12-06T12:08:23.946265Z"
    }
   },
   "outputs": [],
   "source": [
    "## prediction by bert \n",
    "for i in range(10):\n",
    "    print(\"Ground truth result: \",theoritcal_answers[i] )\n",
    "    print(\"Prediction by Bert model: \",predicted_val_answers_by_bert[i] )\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:08:27.600574Z",
     "iopub.status.busy": "2021-12-06T12:08:27.600316Z",
     "iopub.status.idle": "2021-12-06T12:08:27.610328Z",
     "shell.execute_reply": "2021-12-06T12:08:27.609652Z",
     "shell.execute_reply.started": "2021-12-06T12:08:27.600546Z"
    }
   },
   "outputs": [],
   "source": [
    "## prediction by roberta \n",
    "for i in range(10):\n",
    "    print(\"Ground truth result: \",theoritcal_answers[i] )\n",
    "    print(\"Prediction by Robert model: \",predicted_val_answers_by_roberta[i] )\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
