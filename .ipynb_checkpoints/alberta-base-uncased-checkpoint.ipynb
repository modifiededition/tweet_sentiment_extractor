{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-05T14:31:28.037251Z",
     "iopub.status.busy": "2021-12-05T14:31:28.036747Z",
     "iopub.status.idle": "2021-12-05T14:31:28.064792Z",
     "shell.execute_reply": "2021-12-05T14:31:28.064110Z",
     "shell.execute_reply.started": "2021-12-05T14:31:28.037172Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:31:41.313204Z",
     "iopub.status.busy": "2021-12-05T14:31:41.312867Z",
     "iopub.status.idle": "2021-12-05T14:31:41.499951Z",
     "shell.execute_reply": "2021-12-05T14:31:41.499075Z",
     "shell.execute_reply.started": "2021-12-05T14:31:41.313162Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:31:55.177538Z",
     "iopub.status.busy": "2021-12-05T14:31:55.176980Z",
     "iopub.status.idle": "2021-12-05T14:31:55.978042Z",
     "shell.execute_reply": "2021-12-05T14:31:55.976635Z",
     "shell.execute_reply.started": "2021-12-05T14:31:55.177498Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(df_train,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:31:59.779368Z",
     "iopub.status.busy": "2021-12-05T14:31:59.778901Z",
     "iopub.status.idle": "2021-12-05T14:31:59.810175Z",
     "shell.execute_reply": "2021-12-05T14:31:59.809479Z",
     "shell.execute_reply.started": "2021-12-05T14:31:59.779330Z"
    }
   },
   "outputs": [],
   "source": [
    "# filling na values with \"\" \n",
    "X_train.dropna(inplace=True)\n",
    "X_val.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:05.697408Z",
     "iopub.status.busy": "2021-12-05T14:33:05.697130Z",
     "iopub.status.idle": "2021-12-05T14:33:10.811172Z",
     "shell.execute_reply": "2021-12-05T14:33:10.810446Z",
     "shell.execute_reply.started": "2021-12-05T14:33:05.697377Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# using alberta-base tokenizer to tokenize the text into input IDs that model can make sense of.\n",
    "model_checkpoint = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:11.761219Z",
     "iopub.status.busy": "2021-12-05T14:33:11.760653Z",
     "iopub.status.idle": "2021-12-05T14:33:11.810357Z",
     "shell.execute_reply": "2021-12-05T14:33:11.809652Z",
     "shell.execute_reply.started": "2021-12-05T14:33:11.761177Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"alberta_base_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:28.319149Z",
     "iopub.status.busy": "2021-12-05T14:33:28.318368Z",
     "iopub.status.idle": "2021-12-05T14:33:28.805583Z",
     "shell.execute_reply": "2021-12-05T14:33:28.804876Z",
     "shell.execute_reply.started": "2021-12-05T14:33:28.319093Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## converting train and validation pandas dataset into huggingFace Dataset format.\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "validation_data = Dataset.from_pandas(X_val)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:29.293448Z",
     "iopub.status.busy": "2021-12-05T14:33:29.292651Z",
     "iopub.status.idle": "2021-12-05T14:33:29.989925Z",
     "shell.execute_reply": "2021-12-05T14:33:29.989264Z",
     "shell.execute_reply.started": "2021-12-05T14:33:29.293401Z"
    }
   },
   "outputs": [],
   "source": [
    "context = train_data[0][\"text\"]\n",
    "question = train_data[0][\"sentiment\"]\n",
    "\n",
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:35.301374Z",
     "iopub.status.busy": "2021-12-05T14:33:35.300786Z",
     "iopub.status.idle": "2021-12-05T14:33:43.685588Z",
     "shell.execute_reply": "2021-12-05T14:33:43.684762Z",
     "shell.execute_reply.started": "2021-12-05T14:33:35.301333Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to tokenize each sample.\n",
    "def preprocess(example):\n",
    "  return tokenizer(\n",
    "    example[\"sentiment\"],\n",
    "    example[\"text\"],\n",
    "    return_offsets_mapping = True\n",
    ")\n",
    "\n",
    "check_dataset = train_data.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "check_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:33:43.687582Z",
     "iopub.status.busy": "2021-12-05T14:33:43.687244Z",
     "iopub.status.idle": "2021-12-05T14:33:49.108603Z",
     "shell.execute_reply": "2021-12-05T14:33:49.107853Z",
     "shell.execute_reply.started": "2021-12-05T14:33:43.687535Z"
    }
   },
   "outputs": [],
   "source": [
    "## finding the maximum length of a sequece after tokenization\n",
    "MAX_LENGTH = 0\n",
    "for i in check_dataset:\n",
    "  length = len(i[\"input_ids\"])\n",
    "  if length > MAX_LENGTH:\n",
    "    MAX_LENGTH = length\n",
    "    \n",
    "print(\"Max length of a sequence after tokenization: \", MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:35:35.115984Z",
     "iopub.status.busy": "2021-12-05T14:35:35.115117Z",
     "iopub.status.idle": "2021-12-05T14:35:35.128494Z",
     "shell.execute_reply": "2021-12-05T14:35:35.127682Z",
     "shell.execute_reply.started": "2021-12-05T14:35:35.115932Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_training_examples(examples):\n",
    "  inputs = tokenizer(\n",
    "    examples[\"sentiment\"],\n",
    "    examples[\"text\"],\n",
    "    max_length = MAX_LENGTH,\n",
    "    return_offsets_mapping = True,\n",
    "    padding = \"max_length\",\n",
    "    )\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  #print(inputs[\"offset_mapping\"])\n",
    "\n",
    "  for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "\n",
    "    answer = examples[\"selected_text\"][i]\n",
    "    question = examples[\"sentiment\"][i]\n",
    "    context = examples[\"text\"][i]\n",
    "    start_char = 0\n",
    "    end_char  = 0\n",
    "    for idx,ch in enumerate(context):\n",
    "      count = idx\n",
    "      flag = True\n",
    "      for j in answer:\n",
    "        if context[count] == j:\n",
    "          count +=1\n",
    "        else:\n",
    "          flag = False\n",
    "          break\n",
    "      if flag:\n",
    "        start_char = idx\n",
    "        break\n",
    "\n",
    "    end_char = start_char + len(answer)\n",
    "    token_type_ids = inputs[\"token_type_ids\"][i]\n",
    "\n",
    "    idx = 0\n",
    "    try:\n",
    "      while token_type_ids[idx]!=1:\n",
    "        idx+=1\n",
    "      context_start = idx\n",
    "\n",
    "      while token_type_ids[idx] ==1:\n",
    "        idx+=1\n",
    "        if idx == len(token_type_ids):\n",
    "          break\n",
    "      context_end = idx-1\n",
    "    except:\n",
    "      print(token_type_ids)\n",
    "    idx = context_start\n",
    "    while idx <= context_end and offset[idx][0] <= start_char:\n",
    "      idx+=1\n",
    "    start_positions.append(idx-1)\n",
    "    \n",
    "    idx = context_end -1\n",
    "    while idx >= context_start and offset[idx][1] >= end_char:\n",
    "      idx-=1\n",
    "    end_positions.append(idx+1)\n",
    "  \n",
    "  inputs[\"start_positions\"] = start_positions\n",
    "  inputs[\"end_positions\"] = end_positions\n",
    "   \n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:38:16.620324Z",
     "iopub.status.busy": "2021-12-05T14:38:16.619887Z",
     "iopub.status.idle": "2021-12-05T14:38:51.910753Z",
     "shell.execute_reply": "2021-12-05T14:38:51.909966Z",
     "shell.execute_reply.started": "2021-12-05T14:38:16.620281Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_train_data = train_data.map(preprocess_training_examples,batched=True)\n",
    "processed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:38:51.912776Z",
     "iopub.status.busy": "2021-12-05T14:38:51.912500Z",
     "iopub.status.idle": "2021-12-05T14:38:51.922749Z",
     "shell.execute_reply": "2021-12-05T14:38:51.921969Z",
     "shell.execute_reply.started": "2021-12-05T14:38:51.912738Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 20000\n",
    "answer = processed_train_data[idx][\"selected_text\"]\n",
    "\n",
    "start = processed_train_data[idx][\"start_positions\"]\n",
    "end = processed_train_data[idx][\"end_positions\"]\n",
    "labeled_answer = tokenizer.decode(processed_train_data[idx][\"input_ids\"][start : end +1 ])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}\")\n",
    "print(f\"labels give: {labeled_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:38:54.369016Z",
     "iopub.status.busy": "2021-12-05T14:38:54.367478Z",
     "iopub.status.idle": "2021-12-05T14:38:58.316700Z",
     "shell.execute_reply": "2021-12-05T14:38:58.312704Z",
     "shell.execute_reply.started": "2021-12-05T14:38:54.368960Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(preprocess_training_examples, batched = True)\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:39:00.544643Z",
     "iopub.status.busy": "2021-12-05T14:39:00.544135Z",
     "iopub.status.idle": "2021-12-05T14:39:09.458910Z",
     "shell.execute_reply": "2021-12-05T14:39:09.458201Z",
     "shell.execute_reply.started": "2021-12-05T14:39:00.544602Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:39:19.175698Z",
     "iopub.status.busy": "2021-12-05T14:39:19.174889Z",
     "iopub.status.idle": "2021-12-05T14:39:19.473219Z",
     "shell.execute_reply": "2021-12-05T14:39:19.472528Z",
     "shell.execute_reply.started": "2021-12-05T14:39:19.175640Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = processed_train_data.to_tf_dataset(\n",
    "    columns=[\n",
    "        \"input_ids\",\n",
    "        \"start_positions\",\n",
    "        \"end_positions\",\n",
    "        \"attention_mask\",\n",
    "        \"token_type_ids\",\n",
    "    ],\n",
    "    dummy_labels=True,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:39:38.681435Z",
     "iopub.status.busy": "2021-12-05T14:39:38.680653Z",
     "iopub.status.idle": "2021-12-05T14:39:38.708369Z",
     "shell.execute_reply": "2021-12-05T14:39:38.707702Z",
     "shell.execute_reply.started": "2021-12-05T14:39:38.681388Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_epochs = 10\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.001,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "#tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:39:50.286314Z",
     "iopub.status.busy": "2021-12-05T14:39:50.285755Z",
     "iopub.status.idle": "2021-12-05T15:42:21.329362Z",
     "shell.execute_reply": "2021-12-05T15:42:21.328670Z",
     "shell.execute_reply.started": "2021-12-05T14:39:50.286274Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "earlyStop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=1, verbose=0,\n",
    "    mode='auto',baseline=None, restore_best_weights=True\n",
    "    )\n",
    "# We're going to do validation afterwards, so no validation mid-training\n",
    "model.fit(tf_train_dataset, epochs=num_train_epochs,callbacks = [earlyStop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T15:55:55.292633Z",
     "iopub.status.busy": "2021-12-05T15:55:55.292365Z",
     "iopub.status.idle": "2021-12-05T15:55:55.376108Z",
     "shell.execute_reply": "2021-12-05T15:55:55.375126Z",
     "shell.execute_reply.started": "2021-12-05T15:55:55.292603Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"alberta_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T15:57:32.476914Z",
     "iopub.status.busy": "2021-12-05T15:57:32.476629Z",
     "iopub.status.idle": "2021-12-05T15:57:32.482716Z",
     "shell.execute_reply": "2021-12-05T15:57:32.482015Z",
     "shell.execute_reply.started": "2021-12-05T15:57:32.476882Z"
    }
   },
   "outputs": [],
   "source": [
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T15:57:41.140786Z",
     "iopub.status.busy": "2021-12-05T15:57:41.140530Z",
     "iopub.status.idle": "2021-12-05T15:57:43.395123Z",
     "shell.execute_reply": "2021-12-05T15:57:43.394314Z",
     "shell.execute_reply.started": "2021-12-05T15:57:41.140756Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T15:59:42.672351Z",
     "iopub.status.busy": "2021-12-05T15:59:42.671528Z",
     "iopub.status.idle": "2021-12-05T15:59:42.712471Z",
     "shell.execute_reply": "2021-12-05T15:59:42.711754Z",
     "shell.execute_reply.started": "2021-12-05T15:59:42.672298Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:00:03.808418Z",
     "iopub.status.busy": "2021-12-05T16:00:03.807878Z",
     "iopub.status.idle": "2021-12-05T16:00:06.385270Z",
     "shell.execute_reply": "2021-12-05T16:00:06.384512Z",
     "shell.execute_reply.started": "2021-12-05T16:00:03.808376Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_data = Dataset.from_pandas(df_test)\n",
    "\n",
    "processed_test_data = test_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:00:45.531783Z",
     "iopub.status.busy": "2021-12-05T16:00:45.531514Z",
     "iopub.status.idle": "2021-12-05T16:01:08.670031Z",
     "shell.execute_reply": "2021-12-05T16:01:08.669252Z",
     "shell.execute_reply.started": "2021-12-05T16:00:45.531752Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:03:07.005756Z",
     "iopub.status.busy": "2021-12-05T16:03:07.005430Z",
     "iopub.status.idle": "2021-12-05T16:03:07.025571Z",
     "shell.execute_reply": "2021-12-05T16:03:07.024783Z",
     "shell.execute_reply.started": "2021-12-05T16:03:07.005722Z"
    }
   },
   "outputs": [],
   "source": [
    "n_best = 20\n",
    "\n",
    "def predict_answers(inputs):\n",
    "    predicted_answer = []\n",
    "    for i in range(len(inputs[\"offset_mapping\"])):\n",
    "        start_logit = inputs[\"start_logits\"][i]\n",
    "        end_logit = inputs[\"end_logits\"][i]\n",
    "        context = inputs[\"text\"][i]\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "        \n",
    "        flag = False\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # skip answer that are not in the context.\n",
    "                if offset[start_index] is None or offset[end_index] is None:\n",
    "                    continue\n",
    "                # skip answer with length that is either < 0\n",
    "                if end_index < start_index:\n",
    "                    continue\n",
    "                flag = True\n",
    "                answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                predicted_answer.append(answer)\n",
    "                break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            predicted_answer.append(answer)\n",
    "    return {\"predicted_answer\":predicted_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:06:35.519765Z",
     "iopub.status.busy": "2021-12-05T16:06:35.519052Z",
     "iopub.status.idle": "2021-12-05T16:06:35.531356Z",
     "shell.execute_reply": "2021-12-05T16:06:35.530717Z",
     "shell.execute_reply.started": "2021-12-05T16:06:35.519714Z"
    }
   },
   "outputs": [],
   "source": [
    "len(validation_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:08:24.431575Z",
     "iopub.status.busy": "2021-12-05T16:08:24.431331Z",
     "iopub.status.idle": "2021-12-05T16:08:24.583395Z",
     "shell.execute_reply": "2021-12-05T16:08:24.582669Z",
     "shell.execute_reply.started": "2021-12-05T16:08:24.431546Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_val_data.set_format(\"pandas\")\n",
    "\n",
    "processed_val_df =  processed_val_data[:]\n",
    "processed_val_df[\"start_logits\"] = start_logits.tolist()\n",
    "processed_val_df[\"end_logits\"] = end_logits.tolist()\n",
    "\n",
    "processed_val_df[\"text\"] = validation_data[\"text\"]\n",
    "\n",
    "processed_val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:10:10.993635Z",
     "iopub.status.busy": "2021-12-05T16:10:10.993383Z",
     "iopub.status.idle": "2021-12-05T16:10:12.927133Z",
     "shell.execute_reply": "2021-12-05T16:10:12.926467Z",
     "shell.execute_reply.started": "2021-12-05T16:10:10.993608Z"
    }
   },
   "outputs": [],
   "source": [
    "final_val_data = Dataset.from_pandas(processed_val_df)\n",
    "\n",
    "final_val_data = final_val_data.map(predict_answers,batched=True)\n",
    "final_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T16:12:13.434602Z",
     "iopub.status.busy": "2021-12-05T16:12:13.433742Z",
     "iopub.status.idle": "2021-12-05T16:12:13.477191Z",
     "shell.execute_reply": "2021-12-05T16:12:13.476484Z",
     "shell.execute_reply.started": "2021-12-05T16:12:13.434555Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "theoritcal_answers = processed_val_data[\"selected_text\"]\n",
    "\n",
    "# calculating the jaccard score\n",
    "score = 0\n",
    "predicted_val_answers = final_val_data[\"predicted_answer\"]\n",
    "\n",
    "for i in range(len(theoritcal_answers)):\n",
    "    score += jaccard(theoritcal_answers[i],predicted_val_answers[i])\n",
    "    \n",
    "score /= len(theoritcal_answers)\n",
    "print(\"Jaccard score on validation data: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
