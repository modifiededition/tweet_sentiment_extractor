{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.614311Z",
     "iopub.status.busy": "2021-12-06T11:57:49.614058Z",
     "iopub.status.idle": "2021-12-06T11:57:49.630832Z",
     "shell.execute_reply": "2021-12-06T11:57:49.630142Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.614283Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.754385Z",
     "iopub.status.busy": "2021-12-06T11:57:49.753780Z",
     "iopub.status.idle": "2021-12-06T11:57:49.842442Z",
     "shell.execute_reply": "2021-12-06T11:57:49.841769Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.754351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:49.926686Z",
     "iopub.status.busy": "2021-12-06T11:57:49.924916Z",
     "iopub.status.idle": "2021-12-06T11:57:49.932434Z",
     "shell.execute_reply": "2021-12-06T11:57:49.931494Z",
     "shell.execute_reply.started": "2021-12-06T11:57:49.926654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (27481, 4)\n",
      "shape of the test data:  (3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the train data: \", df_train.shape)\n",
    "print(\"shape of the test data: \", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:50.092686Z",
     "iopub.status.busy": "2021-12-06T11:57:50.092466Z",
     "iopub.status.idle": "2021-12-06T11:57:50.106658Z",
     "shell.execute_reply": "2021-12-06T11:57:50.105926Z",
     "shell.execute_reply.started": "2021-12-06T11:57:50.092661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24732, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(df_train,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:50.365204Z",
     "iopub.status.busy": "2021-12-06T11:57:50.364623Z",
     "iopub.status.idle": "2021-12-06T11:57:50.392296Z",
     "shell.execute_reply": "2021-12-06T11:57:50.391650Z",
     "shell.execute_reply.started": "2021-12-06T11:57:50.365172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24731, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "# filling na values with \"\" \n",
    "X_train.dropna(inplace=True)\n",
    "X_val.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:51.349465Z",
     "iopub.status.busy": "2021-12-06T11:57:51.348986Z",
     "iopub.status.idle": "2021-12-06T11:57:51.380292Z",
     "shell.execute_reply": "2021-12-06T11:57:51.379492Z",
     "shell.execute_reply.started": "2021-12-06T11:57:51.349418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['textID', 'text', 'selected_text', 'sentiment'],\n",
       "    num_rows: 24731\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## converting train and validation pandas dataset into huggingFace Dataset format.\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "validation_data = Dataset.from_pandas(X_val)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:00:27.236319Z",
     "iopub.status.busy": "2021-12-06T12:00:27.235699Z",
     "iopub.status.idle": "2021-12-06T12:00:27.247134Z",
     "shell.execute_reply": "2021-12-06T12:00:27.246251Z",
     "shell.execute_reply.started": "2021-12-06T12:00:27.236268Z"
    }
   },
   "outputs": [],
   "source": [
    "n_best = 20\n",
    "\n",
    "def predict_answers(inputs):\n",
    "    predicted_answer = []\n",
    "    for i in range(len(inputs[\"offset_mapping\"])):\n",
    "        start_logit = inputs[\"start_logits\"][i]\n",
    "        end_logit = inputs[\"end_logits\"][i]\n",
    "        context = inputs[\"text\"][i]\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "        \n",
    "        flag = False\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # skip answer that are not in the context.\n",
    "                if offset[start_index] is None or offset[end_index] is None:\n",
    "                    continue\n",
    "                # skip answer with length that is either < 0\n",
    "                if end_index < start_index:\n",
    "                    continue\n",
    "                flag = True\n",
    "                answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                predicted_answer.append(answer)\n",
    "                break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            predicted_answer.append(answer)\n",
    "    return {\"predicted_answer\":predicted_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:54.524528Z",
     "iopub.status.busy": "2021-12-06T11:57:54.524275Z",
     "iopub.status.idle": "2021-12-06T11:57:54.529942Z",
     "shell.execute_reply": "2021-12-06T11:57:54.528964Z",
     "shell.execute_reply.started": "2021-12-06T11:57:54.524500Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Baseline Model: Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:57:55.296275Z",
     "iopub.status.busy": "2021-12-06T11:57:55.296013Z",
     "iopub.status.idle": "2021-12-06T11:58:13.519384Z",
     "shell.execute_reply": "2021-12-06T11:58:13.518568Z",
     "shell.execute_reply.started": "2021-12-06T11:57:55.296247Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at saved_models/bert_base_cased/bert_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_models/bert_base_cased/bert_tokenizer\",local_files_only=True)\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"saved_models/bert_base_cased/bert_model\",local_files_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:13.521813Z",
     "iopub.status.busy": "2021-12-06T11:58:13.521326Z",
     "iopub.status.idle": "2021-12-06T11:58:13.528554Z",
     "shell.execute_reply": "2021-12-06T11:58:13.527884Z",
     "shell.execute_reply.started": "2021-12-06T11:58:13.521775Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 112\n",
    "\n",
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    token_type_ids = inputs[\"token_type_ids\"][i]\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if token_type_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:13.529673Z",
     "iopub.status.busy": "2021-12-06T11:58:13.529412Z",
     "iopub.status.idle": "2021-12-06T11:58:15.535902Z",
     "shell.execute_reply": "2021-12-06T11:58:15.535001Z",
     "shell.execute_reply.started": "2021-12-06T11:58:13.529639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155a77a1bab24ed889494bc9994971ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'offset_mapping', 'selected_text', 'sentiment', 'text', 'textID', 'token_type_ids'],\n",
       "    num_rows: 2749\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:15.538577Z",
     "iopub.status.busy": "2021-12-06T11:58:15.538303Z",
     "iopub.status.idle": "2021-12-06T11:58:15.803495Z",
     "shell.execute_reply": "2021-12-06T11:58:15.802651Z",
     "shell.execute_reply.started": "2021-12-06T11:58:15.538541Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T11:58:15.805372Z",
     "iopub.status.busy": "2021-12-06T11:58:15.805020Z",
     "iopub.status.idle": "2021-12-06T11:58:43.446426Z",
     "shell.execute_reply": "2021-12-06T11:58:43.445675Z",
     "shell.execute_reply.started": "2021-12-06T11:58:15.805335Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:00:35.633240Z",
     "iopub.status.busy": "2021-12-06T12:00:35.632499Z",
     "iopub.status.idle": "2021-12-06T12:00:37.643106Z",
     "shell.execute_reply": "2021-12-06T12:00:37.642448Z",
     "shell.execute_reply.started": "2021-12-06T12:00:35.633203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0bb7e560b64720b40565bd69da655e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'end_logits', 'input_ids', 'offset_mapping', 'predicted_answer', 'selected_text', 'sentiment', 'start_logits', 'text', 'textID', 'token_type_ids'],\n",
       "    num_rows: 2749\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_val_data.set_format(\"pandas\")\n",
    "processed_val_df =  processed_val_data[:]\n",
    "\n",
    "processed_val_df[\"start_logits\"] = start_logits.tolist()\n",
    "processed_val_df[\"end_logits\"] = end_logits.tolist()\n",
    "\n",
    "processed_val_df[\"text\"] = validation_data[\"text\"]\n",
    "\n",
    "bert_final_val_data = Dataset.from_pandas(processed_val_df)\n",
    "\n",
    "bert_final_val_data = bert_final_val_data.map(predict_answers,batched=True)\n",
    "bert_final_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:04:56.137228Z",
     "iopub.status.busy": "2021-12-06T12:04:56.136391Z",
     "iopub.status.idle": "2021-12-06T12:04:56.180208Z",
     "shell.execute_reply": "2021-12-06T12:04:56.179294Z",
     "shell.execute_reply.started": "2021-12-06T12:04:56.137179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score on validation data:  0.6768815054600802\n"
     ]
    }
   ],
   "source": [
    "theoritcal_answers = processed_val_data[\"selected_text\"]\n",
    "\n",
    "# calculating the jaccard score\n",
    "score = 0\n",
    "predicted_val_answers_by_bert = bert_final_val_data[\"predicted_answer\"]\n",
    "for i in range(len(theoritcal_answers)):\n",
    "  score += jaccard(theoritcal_answers[i],predicted_val_answers_by_bert[i])\n",
    "\n",
    "score /= len(theoritcal_answers)\n",
    "print(\"Jaccard score on validation data: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the best model: Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:02:31.523240Z",
     "iopub.status.busy": "2021-12-06T12:02:31.522498Z",
     "iopub.status.idle": "2021-12-06T12:02:39.519020Z",
     "shell.execute_reply": "2021-12-06T12:02:39.518259Z",
     "shell.execute_reply.started": "2021-12-06T12:02:31.523196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
      "\n",
      "All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at saved_models/roberta-base/roberta_base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_models/roberta-base/roberta_base_tokenizer\",local_files_only=True)\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"saved_models/roberta-base/roberta_base\",local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:02:56.441495Z",
     "iopub.status.busy": "2021-12-06T12:02:56.441201Z",
     "iopub.status.idle": "2021-12-06T12:02:56.447834Z",
     "shell.execute_reply": "2021-12-06T12:02:56.446917Z",
     "shell.execute_reply.started": "2021-12-06T12:02:56.441464Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 105\n",
    "\n",
    "def post_porocess_data(examples):\n",
    "  questions = examples[\"sentiment\"]\n",
    "  context = examples[\"text\"]\n",
    "  inputs = tokenizer(\n",
    "      questions,\n",
    "      context,\n",
    "      max_length = MAX_LENGTH,\n",
    "      padding=\"max_length\",\n",
    "      return_offsets_mapping = True,   \n",
    "  )\n",
    "\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "                                  o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "    ]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:07.344151Z",
     "iopub.status.busy": "2021-12-06T12:03:07.343524Z",
     "iopub.status.idle": "2021-12-06T12:03:08.820631Z",
     "shell.execute_reply": "2021-12-06T12:03:08.819802Z",
     "shell.execute_reply.started": "2021-12-06T12:03:07.344112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1bf067042e4b248ff08193826ff41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'offset_mapping', 'selected_text', 'sentiment', 'text', 'textID'],\n",
       "    num_rows: 2749\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_val_data = validation_data.map(\n",
    "    post_porocess_data,\n",
    "    batched = True\n",
    ")\n",
    "processed_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:16.056052Z",
     "iopub.status.busy": "2021-12-06T12:03:16.053625Z",
     "iopub.status.idle": "2021-12-06T12:03:16.091317Z",
     "shell.execute_reply": "2021-12-06T12:03:16.090628Z",
     "shell.execute_reply.started": "2021-12-06T12:03:16.056012Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_dataset = processed_val_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:25.180679Z",
     "iopub.status.busy": "2021-12-06T12:03:25.180400Z",
     "iopub.status.idle": "2021-12-06T12:03:43.245669Z",
     "shell.execute_reply": "2021-12-06T12:03:43.244871Z",
     "shell.execute_reply.started": "2021-12-06T12:03:25.180649Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(tf_eval_dataset)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:03:49.755271Z",
     "iopub.status.busy": "2021-12-06T12:03:49.755008Z",
     "iopub.status.idle": "2021-12-06T12:03:50.833955Z",
     "shell.execute_reply": "2021-12-06T12:03:50.833275Z",
     "shell.execute_reply.started": "2021-12-06T12:03:49.755243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea25b035e54497a9a7f6599afe1b7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'end_logits', 'input_ids', 'offset_mapping', 'predicted_answer', 'selected_text', 'sentiment', 'start_logits', 'text', 'textID'],\n",
       "    num_rows: 2749\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_val_data.set_format(\"pandas\")\n",
    "processed_val_df =  processed_val_data[:]\n",
    "\n",
    "processed_val_df[\"start_logits\"] = start_logits.tolist()\n",
    "processed_val_df[\"end_logits\"] = end_logits.tolist()\n",
    "\n",
    "processed_val_df[\"text\"] = validation_data[\"text\"]\n",
    "\n",
    "roberta_final_val_data = Dataset.from_pandas(processed_val_df)\n",
    "\n",
    "roberta_final_val_data = roberta_final_val_data.map(predict_answers,batched=True)\n",
    "roberta_final_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:04:58.777982Z",
     "iopub.status.busy": "2021-12-06T12:04:58.777211Z",
     "iopub.status.idle": "2021-12-06T12:04:58.813397Z",
     "shell.execute_reply": "2021-12-06T12:04:58.812677Z",
     "shell.execute_reply.started": "2021-12-06T12:04:58.777943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score on validation data:  0.7180039345097456\n"
     ]
    }
   ],
   "source": [
    "# calculating the jaccard score\n",
    "score = 0\n",
    "predicted_val_answers_by_roberta = roberta_final_val_data[\"predicted_answer\"]\n",
    "for i in range(len(theoritcal_answers)):\n",
    "  score += jaccard(theoritcal_answers[i],predicted_val_answers_by_roberta[i])\n",
    "\n",
    "score /= len(theoritcal_answers)\n",
    "print(\"Jaccard score on validation data: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison on predictions between basline model-bert and the best model roberta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:11:13.800585Z",
     "iopub.status.busy": "2021-12-06T12:11:13.800310Z",
     "iopub.status.idle": "2021-12-06T12:11:13.806714Z",
     "shell.execute_reply": "2021-12-06T12:11:13.805662Z",
     "shell.execute_reply.started": "2021-12-06T12:11:13.800555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------------------+\n",
      "|       Model        | Jaccard score on validation data |\n",
      "+--------------------+----------------------------------+\n",
      "|  Bert-base-cased   |               0.67               |\n",
      "| Roberta-base-cased |               0.71               |\n",
      "+--------------------+----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Jaccard score on validation data\"]\n",
    "x.add_row([\"Bert-base-cased\", 0.67])\n",
    "x.add_row([\"Roberta-base-cased\", 0.71])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:08:23.946294Z",
     "iopub.status.busy": "2021-12-06T12:08:23.946021Z",
     "iopub.status.idle": "2021-12-06T12:08:23.957988Z",
     "shell.execute_reply": "2021-12-06T12:08:23.957214Z",
     "shell.execute_reply.started": "2021-12-06T12:08:23.946265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth result:  t?  lovelovelove\n",
      "Prediction by Bert model:  lovelovelove<3\n",
      "**************************************************\n",
      "Ground truth result:  resting had a whole day of walking\n",
      "Prediction by Bert model:  resting had a whole day of walking\n",
      "**************************************************\n",
      "Ground truth result:  was in Palawan a couple of days ago, i`ll try to post pictures tom.\n",
      "Prediction by Bert model:  was in Palawan a couple of days ago, i`ll try to post pictures tom.\n",
      "**************************************************\n",
      "Ground truth result:  horrible.\n",
      "Prediction by Bert model:  its horrible. DON`T TELL ON ME!\n",
      "**************************************************\n",
      "Ground truth result:  glad\n",
      "Prediction by Bert model:  Glad\n",
      "**************************************************\n",
      "Ground truth result:  Are the drugs working?\n",
      "Prediction by Bert model:  Are the drugs working?\n",
      "**************************************************\n",
      "Ground truth result:  if not idgaf\n",
      "Prediction by Bert model:  if not idgaf\n",
      "**************************************************\n",
      "Ground truth result:  l I look forward\n",
      "Prediction by Bert model:  Well I look forward to chatting with you when our wakeful hours overlap.\n",
      "**************************************************\n",
      "Ground truth result:  huh?\n",
      "Prediction by Bert model:  I bet its cool down in SR, huh? It`s not here. I haven`t stopped sweating\n",
      "**************************************************\n",
      "Ground truth result:  wee. done with advance audit paper\n",
      "Prediction by Bert model:  wee. done with advance audit paper\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "## prediction by bert \n",
    "for i in range(10):\n",
    "    print(\"Ground truth result: \",theoritcal_answers[i] )\n",
    "    print(\"Prediction by Bert model: \",predicted_val_answers_by_bert[i] )\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-06T12:08:27.600574Z",
     "iopub.status.busy": "2021-12-06T12:08:27.600316Z",
     "iopub.status.idle": "2021-12-06T12:08:27.610328Z",
     "shell.execute_reply": "2021-12-06T12:08:27.609652Z",
     "shell.execute_reply.started": "2021-12-06T12:08:27.600546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth result:  t?  lovelovelove\n",
      "Prediction by Robert model:  ?  lovelovelove\n",
      "**************************************************\n",
      "Ground truth result:  resting had a whole day of walking\n",
      "Prediction by Robert model:  resting had a whole day of walking\n",
      "**************************************************\n",
      "Ground truth result:  was in Palawan a couple of days ago, i`ll try to post pictures tom.\n",
      "Prediction by Robert model:  was in Palawan a couple of days ago, i`ll try to post pictures tom.\n",
      "**************************************************\n",
      "Ground truth result:  horrible.\n",
      "Prediction by Robert model:  horrible.\n",
      "**************************************************\n",
      "Ground truth result:  glad\n",
      "Prediction by Robert model:  Glad\n",
      "**************************************************\n",
      "Ground truth result:  Are the drugs working?\n",
      "Prediction by Robert model:  Are the drugs working?\n",
      "**************************************************\n",
      "Ground truth result:  if not idgaf\n",
      "Prediction by Robert model:  deleted\n",
      "**************************************************\n",
      "Ground truth result:  l I look forward\n",
      "Prediction by Robert model:  I look forward\n",
      "**************************************************\n",
      "Ground truth result:  huh?\n",
      "Prediction by Robert model:  It`s not here.\n",
      "**************************************************\n",
      "Ground truth result:  wee. done with advance audit paper\n",
      "Prediction by Robert model:  wee. done with advance audit paper\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "## prediction by roberta \n",
    "for i in range(10):\n",
    "    print(\"Ground truth result: \",theoritcal_answers[i] )\n",
    "    print(\"Prediction by Robert model: \",predicted_val_answers_by_roberta[i] )\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
