{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba888c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0125c34",
   "metadata": {},
   "source": [
    "## 1. Getting predictions on raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a386cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_1(X):\n",
    "    \"\"\"\n",
    "        Argument-> X as python dictionary with 2 keys as text(context) and sentiment(question) and their values as list \n",
    "            of strings.\n",
    "        Return-> Extracted word/phrase (answer) from the text(context) based on the sentiment(question).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pre-Processing raw data for final predictions.\n",
    "    \n",
    "    # converting simple python dictionary to huggingface dataset format.\n",
    "    \n",
    "    dataset = Dataset.from_dict(X)\n",
    "    \n",
    "    MAX_LENGTH = 105\n",
    "    \n",
    "    # loading saved roberta-base tokenizer to tokenize the text into input IDs that model can make sense of.\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"saved_models/roberta-base/roberta_base_tokenizer\",local_files_only =True)\n",
    "    \n",
    "    def process_data(examples):\n",
    "        questions = examples[\"sentiment\"]\n",
    "        context = examples[\"text\"]\n",
    "        inputs = tokenizer(\n",
    "            questions,\n",
    "            context,\n",
    "            max_length = MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping = True,   \n",
    "        )\n",
    "        # Assigning None values to all offset mapping of tokens which are not the context tokens.\n",
    "        for i in range(len(inputs[\"input_ids\"])):\n",
    "            offset = inputs[\"offset_mapping\"][i]\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "            inputs[\"offset_mapping\"][i] = [\n",
    "                o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "            ]\n",
    "        return inputs\n",
    "    \n",
    "    processed_raw_data = dataset.map(\n",
    "        process_data,\n",
    "        batched = True\n",
    "    )\n",
    "    \n",
    "    # converting dataset format into tf dataset.\n",
    "    tf_raw_dataset = processed_raw_data.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        shuffle=False,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "    # loading saved roberta-base model\n",
    "    model = TFAutoModelForQuestionAnswering.from_pretrained(\"saved_models/roberta-base/roberta_base\",local_files_only=True)\n",
    "    \n",
    "    # final predictions.\n",
    "    outputs = model.predict(tf_raw_dataset)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    \n",
    "    # Post Processing.\n",
    "    # Using start_logits and end_logits to generate the final answer from the given context.\n",
    "    n_best = 20\n",
    "\n",
    "    def predict_answers(inputs):\n",
    "        predicted_answer = []\n",
    "        for i in range(len(inputs[\"offset_mapping\"])):\n",
    "            start_logit = inputs[\"start_logits\"][i]\n",
    "            end_logit = inputs[\"end_logits\"][i]\n",
    "            context = inputs[\"text\"][i]\n",
    "            offset = inputs[\"offset_mapping\"][i]\n",
    "            start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "\n",
    "            flag = False\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # skip answer that are not in the context.\n",
    "                    if offset[start_index] is None or offset[end_index] is None:\n",
    "                        continue\n",
    "                    # skip answer with length that is either < 0\n",
    "                    if end_index < start_index:\n",
    "                        continue\n",
    "                    flag = True\n",
    "                    answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                    predicted_answer.append(answer)\n",
    "                    break\n",
    "                if flag:\n",
    "                    break\n",
    "            if not flag:\n",
    "                predicted_answer.append(answer)\n",
    "        return {\"predicted_answer\":predicted_answer}\n",
    "    \n",
    "    processed_raw_data.set_format(\"pandas\")\n",
    "    \n",
    "    processed_raw_df =  processed_raw_data[:]\n",
    "    processed_raw_df[\"start_logits\"] = start_logits.tolist()\n",
    "    processed_raw_df[\"end_logits\"] = end_logits.tolist()\n",
    "    processed_raw_df[\"text\"] = X[\"text\"]\n",
    "    \n",
    "    final_data = Dataset.from_pandas(processed_raw_df)\n",
    "    final_data = final_data.map(predict_answers,batched=True)\n",
    "    \n",
    "    return final_data[\"predicted_answer\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c80d03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b7b18424eb41cdb2d9c03fd86f2c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
      "\n",
      "All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at saved_models/roberta-base/roberta_base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7405c118e94485c80a1045a328a254e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['good joke', 'bad.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {\"text\":[\"Well this is a good joke\",\"This movie is very bad.\"], \"sentiment\":[\"positive\",\"negative\"]}\n",
    "final_func_1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843004d",
   "metadata": {},
   "source": [
    "## 2. Evaluating performance on raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28e26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_2(X,Y):\n",
    "    \n",
    "    \"\"\"\n",
    "        Argument-> X as python dictionary with 2 keys as text(context) and sentiment(question) and their values as list \n",
    "            of strings.\n",
    "        Argument- Y as list of answers to the questions given in the context.\n",
    "        \n",
    "        Return-> jaccard score between predictions and ground truth.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pre-Processing raw data for final predictions.\n",
    "    \n",
    "    # converting simple python dictionary to huggingface dataset format.\n",
    "    \n",
    "    dataset = Dataset.from_dict(X)\n",
    "    \n",
    "    MAX_LENGTH = 105\n",
    "    \n",
    "    # loading saved roberta-base tokenizer to tokenize the text into input IDs that model can make sense of.\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"saved_models/roberta-base/roberta_base_tokenizer\",local_files_only =True)\n",
    "    \n",
    "    def process_data(examples):\n",
    "        questions = examples[\"sentiment\"]\n",
    "        context = examples[\"text\"]\n",
    "        inputs = tokenizer(\n",
    "            questions,\n",
    "            context,\n",
    "            max_length = MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping = True,   \n",
    "        )\n",
    "        # Assigning None values to all offset mapping of tokens which are not the context tokens.\n",
    "        for i in range(len(inputs[\"input_ids\"])):\n",
    "            offset = inputs[\"offset_mapping\"][i]\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "            inputs[\"offset_mapping\"][i] = [\n",
    "                o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "            ]\n",
    "        return inputs\n",
    "    \n",
    "    processed_raw_data = dataset.map(\n",
    "        process_data,\n",
    "        batched = True\n",
    "    )\n",
    "    \n",
    "    # converting dataset format into tf dataset.\n",
    "    tf_raw_dataset = processed_raw_data.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        shuffle=False,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "    # loading saved roberta-base model\n",
    "    model = TFAutoModelForQuestionAnswering.from_pretrained(\"saved_models/roberta-base/roberta_base\",local_files_only=True)\n",
    "    \n",
    "    # final predictions.\n",
    "    outputs = model.predict(tf_raw_dataset)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    \n",
    "    # Post Processing.\n",
    "    # Using start_logits and end_logits to generate the final answer from the given context.\n",
    "    n_best = 20\n",
    "\n",
    "    def predict_answers(inputs):\n",
    "        predicted_answer = []\n",
    "        for i in range(len(inputs[\"offset_mapping\"])):\n",
    "            start_logit = inputs[\"start_logits\"][i]\n",
    "            end_logit = inputs[\"end_logits\"][i]\n",
    "            context = inputs[\"text\"][i]\n",
    "            offset = inputs[\"offset_mapping\"][i]\n",
    "            start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "\n",
    "            flag = False\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # skip answer that are not in the context.\n",
    "                    if offset[start_index] is None or offset[end_index] is None:\n",
    "                        continue\n",
    "                    # skip answer with length that is either < 0\n",
    "                    if end_index < start_index:\n",
    "                        continue\n",
    "                    flag = True\n",
    "                    answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                    predicted_answer.append(answer)\n",
    "                    break\n",
    "                if flag:\n",
    "                    break\n",
    "            if not flag:\n",
    "                predicted_answer.append(context)\n",
    "        return {\"predicted_answer\":predicted_answer}\n",
    "    \n",
    "    processed_raw_data.set_format(\"pandas\")\n",
    "    \n",
    "    processed_raw_df =  processed_raw_data[:]\n",
    "    processed_raw_df[\"start_logits\"] = start_logits.tolist()\n",
    "    processed_raw_df[\"end_logits\"] = end_logits.tolist()\n",
    "    processed_raw_df[\"text\"] = X[\"text\"]\n",
    "    \n",
    "    final_data = Dataset.from_pandas(processed_raw_df)\n",
    "    final_data = final_data.map(predict_answers,batched=True)\n",
    "    \n",
    "    \n",
    "    # defining jaccard score\n",
    "    def jaccard(str1, str2): \n",
    "        a = set(str1.lower().split()) \n",
    "        b = set(str2.lower().split())\n",
    "        if (len(a)==0) & (len(b)==0): return 0.5\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    \n",
    "    \n",
    "    theoritcal_answers = Y\n",
    "    predicted_val_answers = final_data[\"predicted_answer\"]\n",
    "    # calculating the jaccard score\n",
    "    score = 0\n",
    "    for i in range(len(theoritcal_answers)):\n",
    "        score += jaccard(theoritcal_answers[i],predicted_val_answers[i])\n",
    "    \n",
    "    score /= len(theoritcal_answers)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b0f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"text\": ['Glad I went out, glad I didn`t leave early, and glad to be afterpartying it up @ Beth`s  I`m back!',\n",
    "             ' I know! I`m so slow its horrible. DON`T TELL ON ME!'],\n",
    "    \"sentiment\":[\"positive\",\"negative\"]}\n",
    "y = [\"glad\",\"horrible.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff26111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed270af59144935acf898fe63e44217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
      "\n",
      "All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at saved_models/roberta-base/roberta_base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec404a5d69e43e79bcd15df518f1874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score between predictions and ground truth:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard score between predictions and ground truth: \", final_func_2(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3d13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
