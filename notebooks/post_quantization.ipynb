{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc05c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd009f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd8faea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (27481, 4)\n",
      "shape of the test data:  (3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the train data: \", df_train.shape)\n",
    "print(\"shape of the test data: \", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6986da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24732, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(df_train,test_size=0.1,random_state=42)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9659c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (24731, 4)\n",
      "Shape of the validation data:  (2749, 4)\n"
     ]
    }
   ],
   "source": [
    "# filling na values with \"\" \n",
    "X_train.dropna(inplace=True)\n",
    "X_val.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape of the train data: \", X_train.shape)\n",
    "print(\"Shape of the validation data: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35c9b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['textID', 'text', 'selected_text', 'sentiment'],\n",
       "    num_rows: 24731\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## converting train and validation pandas dataset into huggingFace Dataset format.\n",
    "\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "validation_data = Dataset.from_pandas(X_val)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d849bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best = 20\n",
    "\n",
    "def predict_answers(inputs):\n",
    "    predicted_answer = []\n",
    "    for i in range(len(inputs[\"offset_mapping\"])):\n",
    "        start_logit = inputs[\"start_logits\"][i]\n",
    "        end_logit = inputs[\"end_logits\"][i]\n",
    "        context = inputs[\"text\"][i]\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        start_indexes = np.argsort(start_logit)[-1: -n_best - 1:-1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "        \n",
    "        flag = False\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # skip answer that are not in the context.\n",
    "                if offset[start_index] is None or offset[end_index] is None:\n",
    "                    continue\n",
    "                # skip answer with length that is either < 0\n",
    "                if end_index < start_index:\n",
    "                    continue\n",
    "                flag = True\n",
    "                answer = context[offset[start_index][0]: offset[end_index][1]]\n",
    "                predicted_answer.append(answer)\n",
    "                break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            predicted_answer.append(answer)\n",
    "    return {\"predicted_answer\":predicted_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f1ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a7daa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
      "\n",
      "All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at saved_models/roberta-base/roberta_base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_models/roberta-base/roberta_base_tokenizer\",local_files_only=True)\n",
    "\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"saved_models/roberta-base/roberta_base\",local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6def8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527bf16",
   "metadata": {},
   "source": [
    "### 1. Convert to a Tensorflow Lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f80598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
